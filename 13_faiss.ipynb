{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c814dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_nlist: int = 1000\n",
    "model_file = \"models/word2vec/20230126_103746/lightning_logs/version_0/checkpoints/pytorch_model.bin\"\n",
    "index_file = \"output/item.index\"\n",
    "em_file = \"output/em.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2fdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f774ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'global_step': 12110, 'pytorch-lightning_version': '1.7.7', 'state_dict': OrderedDict([('word_embeddings.weight', tensor([[ 0.2630, -0.0449,  0.6082,  ...,  0.4589,  0.3399, -0.3081],\n",
      "        [ 0.0128,  0.6311,  0.2702,  ...,  0.2637, -0.2946, -0.0521],\n",
      "        [-0.1858, -0.0423,  0.1846,  ..., -0.1649, -0.1736, -0.2905],\n",
      "        ...,\n",
      "        [ 0.0516, -0.3595, -0.1154,  ..., -0.4182, -0.4185, -0.0857],\n",
      "        [ 0.2802,  0.5586,  0.0309,  ..., -0.2533,  0.0147, -0.5825],\n",
      "        [-0.7261,  0.1738, -0.0546,  ..., -0.0231, -0.9209, -0.0161]])), ('type_embeddings.weight', tensor([[-9.4777e-03,  2.8200e-03,  1.7705e-02, -4.7742e-02,  5.0185e-02,\n",
      "          2.3823e-02, -4.4638e-02,  3.4346e-02,  2.0280e-02,  2.7702e-02,\n",
      "         -1.6176e-02,  8.0596e-03,  7.8067e-03,  5.3401e-02,  6.1753e-02,\n",
      "          2.4924e-01,  2.1415e-02,  2.8027e-02, -2.0764e-02,  7.1716e-03,\n",
      "         -3.8487e-02,  8.6159e-04,  3.1261e-02, -1.7734e-02, -3.2709e-02,\n",
      "          1.9222e-03, -1.5777e-02, -2.9126e-02,  1.4726e-02,  4.4977e-02,\n",
      "          5.2790e-02,  9.4492e-03],\n",
      "        [-2.8300e-02,  1.1916e-02,  1.2551e+00, -9.2922e-02,  8.0333e-02,\n",
      "          9.5177e-02, -1.4004e-01,  7.4137e-02,  1.0893e+00,  1.0722e-01,\n",
      "         -1.5780e-02, -7.3175e-03, -4.7157e-03,  9.4168e-02,  2.5167e-01,\n",
      "         -9.4349e+00,  4.0528e-02,  7.7220e-02, -2.6340e-02,  2.5221e-02,\n",
      "         -1.1240e-01,  4.5270e-02,  9.8072e-02, -7.6681e-02, -8.4689e-01,\n",
      "          7.4619e-03, -1.1729e+00, -6.1662e-02,  4.6148e-03,  1.4405e-01,\n",
      "          1.9584e-01,  5.2582e-02],\n",
      "        [ 1.9687e-02, -3.7217e-02,  1.5730e+00, -1.2964e-01,  1.0175e-01,\n",
      "          6.8887e-02, -9.7808e-02,  4.0117e-02,  1.3848e+00,  6.2892e-02,\n",
      "         -6.3876e-03, -2.3435e-02,  5.6617e-02,  3.6402e-02,  2.2614e-01,\n",
      "         -1.3235e+01,  4.6811e-02,  3.2812e-02, -3.3635e-02,  3.3734e-02,\n",
      "         -9.9604e-02,  6.8421e-02,  9.3190e-02, -9.2255e-02, -9.8396e-01,\n",
      "          5.8013e-02, -1.5172e+00, -6.2506e-02,  2.4322e-02,  7.8069e-02,\n",
      "          1.6529e-01,  3.2468e-02]]))]), 'loops': {'fit_loop': {'state_dict': {}, 'epoch_loop.state_dict': {'_batches_that_stepped': 12110}, 'epoch_loop.batch_progress': {'total': {'ready': 12110, 'completed': 12110, 'started': 12110, 'processed': 12110}, 'current': {'ready': 6055, 'completed': 6055, 'started': 6055, 'processed': 6055}, 'is_last_batch': True}, 'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.batch_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.optim_progress': {'optimizer': {'step': {'total': {'ready': 12110, 'completed': 12110}, 'current': {'ready': 6055, 'completed': 6055}}, 'zero_grad': {'total': {'ready': 12110, 'completed': 12110, 'started': 12110}, 'current': {'ready': 6055, 'completed': 6055, 'started': 6055}}}, 'optimizer_position': 1}, 'epoch_loop.batch_loop.manual_loop.state_dict': {}, 'epoch_loop.batch_loop.manual_loop.optim_step_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.val_loop.state_dict': {}, 'epoch_loop.val_loop.dataloader_progress': {'total': {'ready': 2, 'completed': 2}, 'current': {'ready': 1, 'completed': 1}}, 'epoch_loop.val_loop.epoch_loop.state_dict': {}, 'epoch_loop.val_loop.epoch_loop.batch_progress': {'total': {'ready': 124, 'completed': 124, 'started': 124, 'processed': 124}, 'current': {'ready': 124, 'completed': 124, 'started': 124, 'processed': 124}, 'is_last_batch': True}, 'epoch_progress': {'total': {'ready': 2, 'completed': 1, 'started': 2, 'processed': 2}, 'current': {'ready': 2, 'completed': 1, 'started': 2, 'processed': 2}}}, 'validate_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'test_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'predict_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}}, 'callbacks': {\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 0, 'stopped_epoch': 0, 'best_score': tensor(6.1621), 'patience': 0}, \"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\": {'monitor': 'val_loss', 'best_model_score': tensor(6.1621), 'best_model_path': 'models/word2vec/20230126_103746/lightning_logs/version_0/checkpoints/epoch=1-step=12110.ckpt', 'current_score': tensor(6.1621), 'dirpath': 'models/word2vec/20230126_103746/lightning_logs/version_0/checkpoints', 'best_k_models': {'models/word2vec/20230126_103746/lightning_logs/version_0/checkpoints/epoch=1-step=12110.ckpt': tensor(6.1621)}, 'kth_best_model_path': 'models/word2vec/20230126_103746/lightning_logs/version_0/checkpoints/epoch=1-step=12110.ckpt', 'kth_value': tensor(6.1621), 'last_model_path': ''}}, 'optimizer_states': [{'state': {0: {'step': tensor(12110.), 'exp_avg': tensor([[ 1.4317e-05,  5.8535e-06, -8.5829e-06,  ...,  2.7861e-06,\n",
      "          5.4987e-06,  1.3585e-05],\n",
      "        [-2.2709e-06, -5.3189e-06,  8.3703e-06,  ..., -1.4851e-06,\n",
      "          9.1083e-07,  3.0658e-06],\n",
      "        [ 1.3531e-06, -2.2839e-07,  2.0764e-05,  ..., -4.3892e-06,\n",
      "         -5.3850e-07, -8.3492e-06],\n",
      "        ...,\n",
      "        [-1.1351e-09,  4.2479e-08,  1.0503e-09,  ...,  2.7068e-08,\n",
      "         -3.1294e-11,  3.8908e-09],\n",
      "        [-1.1785e-06, -8.0885e-06,  8.8271e-06,  ...,  1.3607e-07,\n",
      "          2.9293e-06, -3.3277e-06],\n",
      "        [ 8.6564e-09,  1.0805e-08,  3.7721e-08,  ...,  1.3446e-08,\n",
      "          1.3054e-08, -7.7891e-09]]), 'exp_avg_sq': tensor([[1.2309e-09, 1.0826e-09, 3.1793e-09,  ..., 1.0751e-09, 1.1097e-09,\n",
      "         1.0760e-09],\n",
      "        [5.9975e-10, 6.5069e-10, 4.1693e-09,  ..., 6.7935e-10, 1.0035e-09,\n",
      "         7.1551e-10],\n",
      "        [1.5872e-09, 1.6862e-09, 5.6649e-09,  ..., 1.5966e-09, 1.6204e-09,\n",
      "         1.6040e-09],\n",
      "        ...,\n",
      "        [5.5662e-11, 5.2618e-11, 6.2083e-11,  ..., 5.8786e-11, 3.5793e-11,\n",
      "         5.0749e-11],\n",
      "        [1.3554e-10, 1.2156e-10, 7.3866e-11,  ..., 2.7318e-10, 1.0136e-10,\n",
      "         9.5293e-11],\n",
      "        [1.2037e-11, 5.3387e-11, 2.4296e-11,  ..., 1.2013e-11, 1.2841e-11,\n",
      "         1.4417e-11]])}, 1: {'step': tensor(12110.), 'exp_avg': tensor([[ 3.1953e-03,  3.0467e-02,  2.6701e-02,  2.9947e-02,  6.0433e-03,\n",
      "          3.4758e-02, -1.7628e-03,  1.3965e-02,  4.0145e-02,  8.0668e-03,\n",
      "          9.3509e-02, -5.2181e-03,  3.2422e-02, -6.2064e-02, -2.6297e-02,\n",
      "         -2.5872e-01, -4.7067e-03,  7.3550e-03,  7.1909e-03,  4.8601e-02,\n",
      "         -5.3761e-02,  4.9561e-02, -1.9222e-02, -1.3572e-02, -2.9072e-02,\n",
      "          2.8456e-02, -8.1518e-02,  2.5949e-02, -1.2234e-02,  1.3683e-03,\n",
      "          1.9049e-02,  1.1411e-02],\n",
      "        [ 1.2138e-02, -4.4043e-04,  6.4431e-03,  2.5782e-04,  6.8965e-03,\n",
      "         -3.8398e-03,  5.5133e-03, -1.1616e-03,  5.0187e-03, -1.1513e-02,\n",
      "          5.5950e-03,  7.3652e-03,  2.0733e-03, -8.9635e-03,  4.4640e-03,\n",
      "          4.4942e-03,  1.9204e-03, -9.4726e-03,  1.1051e-02, -4.3416e-03,\n",
      "         -2.8712e-03, -7.8779e-03,  7.7775e-03, -2.7862e-03,  3.2976e-03,\n",
      "         -2.2737e-03,  8.6343e-04, -1.7556e-03,  6.7736e-03,  1.5414e-03,\n",
      "         -4.7125e-04, -1.5408e-03],\n",
      "        [-3.3262e-04,  4.1005e-03, -4.7105e-04, -1.8613e-03, -8.7752e-04,\n",
      "         -6.6917e-04, -2.1076e-03, -7.2903e-04, -7.8229e-04, -4.4782e-03,\n",
      "          1.4688e-03,  1.7625e-03, -8.0237e-04,  2.8811e-03, -8.6379e-04,\n",
      "          3.1285e-03,  2.9641e-03, -3.8792e-04, -3.1137e-03,  3.7419e-03,\n",
      "          1.9955e-03,  1.1616e-05, -1.1928e-03,  1.3144e-03,  5.7811e-04,\n",
      "         -1.6580e-03, -9.7953e-04, -1.0126e-03,  2.9214e-03, -2.2311e-03,\n",
      "         -1.9491e-03,  3.1353e-03]]), 'exp_avg_sq': tensor([[1.2103e-03, 1.2345e-03, 2.0737e-03, 1.2102e-03, 1.2113e-03, 1.2864e-03,\n",
      "         1.1369e-03, 1.1498e-03, 2.1130e-03, 1.0965e-03, 1.9158e-03, 1.1399e-03,\n",
      "         1.2791e-03, 1.5291e-03, 1.0608e-03, 3.2305e-02, 1.1773e-03, 1.1988e-03,\n",
      "         1.1462e-03, 1.3811e-03, 1.4409e-03, 1.4329e-03, 1.1441e-03, 1.2043e-03,\n",
      "         1.6233e-03, 1.2689e-03, 2.5700e-03, 1.2349e-03, 1.1844e-03, 1.0525e-03,\n",
      "         1.1396e-03, 1.1483e-03],\n",
      "        [3.1037e-05, 1.2775e-05, 1.3302e-05, 1.2946e-05, 1.6650e-05, 1.4607e-05,\n",
      "         1.4741e-05, 1.3785e-05, 1.3283e-05, 2.5796e-05, 1.7511e-05, 1.8810e-05,\n",
      "         1.3508e-05, 2.0706e-05, 1.3356e-05, 9.3591e-06, 1.3642e-05, 2.0017e-05,\n",
      "         2.4999e-05, 1.6975e-05, 1.3100e-05, 1.9233e-05, 1.8802e-05, 1.3719e-05,\n",
      "         1.3056e-05, 1.4199e-05, 1.0734e-05, 1.3860e-05, 1.7532e-05, 1.3051e-05,\n",
      "         1.2449e-05, 1.3911e-05],\n",
      "        [4.7183e-06, 6.5763e-06, 3.6587e-06, 4.6982e-06, 4.3870e-06, 4.8659e-06,\n",
      "         4.6234e-06, 4.3982e-06, 3.8836e-06, 7.0486e-06, 4.7025e-06, 4.8746e-06,\n",
      "         4.6876e-06, 5.4323e-06, 3.8228e-06, 3.5718e-06, 5.1214e-06, 4.8211e-06,\n",
      "         5.6646e-06, 5.7925e-06, 4.5408e-06, 4.4676e-06, 4.3231e-06, 4.7384e-06,\n",
      "         3.8186e-06, 4.7847e-06, 3.6124e-06, 4.7251e-06, 5.2014e-06, 4.5421e-06,\n",
      "         4.1148e-06, 5.6040e-06]])}}, 'param_groups': [{'lr': 0.005, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': [0, 1]}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}]}], 'lr_schedulers': []}\n"
     ]
    }
   ],
   "source": [
    "ckp = torch.load(str(model_file))\n",
    "print(ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bbf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1855603/1855603 [00:11<00:00, 166527.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_em.shape=(1855603, 32)\n",
      "type_em.shape=(3, 32)\n",
      "em.shape=(5566809, 32)\n"
     ]
    }
   ],
   "source": [
    "word_em = ckp[\"state_dict\"][\"word_embeddings.weight\"].cpu().numpy()\n",
    "type_em = ckp[\"state_dict\"][\"type_embeddings.weight\"].cpu().numpy()\n",
    "em = []\n",
    "for wem in tqdm(word_em):\n",
    "    for tem in type_em:\n",
    "        em.append(wem + tem)\n",
    "em = np.array(em, dtype=np.float32)\n",
    "print(f\"word_em.shape={word_em.shape}\\ntype_em.shape={type_em.shape}\\nem.shape={em.shape}\")\n",
    "assert word_em.shape[0] * type_em.shape[0] == em.shape[0]\n",
    "faiss.normalize_L2(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cae12d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 956 ms, sys: 2.13 s, total: 3.08 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save(em_file, em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60a2888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training level-1 quantizer\n",
      "Training level-1 quantizer on 5566809 vectors in 32D\n",
      "Training IVF residual\n",
      "  Input training set too big (max size is 65536), sampling 65536 / 5566809 vectors\n",
      "computing residuals\n",
      "training 8x256 product quantizer on 65536 vectors in 32D\n",
      "Training PQ slice 0/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 24 (0.44 s, search 0.40 s): objective=238.139 imbalance=1.654 nsplit=0       \n",
      "Training PQ slice 1/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 24 (0.43 s, search 0.39 s): objective=246.085 imbalance=1.678 nsplit=0       \n",
      "Training PQ slice 2/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 24 (0.48 s, search 0.44 s): objective=234.466 imbalance=1.682 nsplit=0       \n",
      "Training PQ slice 3/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 24 (0.39 s, search 0.36 s): objective=177.125 imbalance=1.563 nsplit=0       \n",
      "Training PQ slice 4/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 24 (0.50 s, search 0.46 s): objective=239.975 imbalance=1.649 nsplit=0       \n",
      "Training PQ slice 5/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 24 (0.37 s, search 0.34 s): objective=246.192 imbalance=1.646 nsplit=0       \n",
      "Training PQ slice 6/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 24 (0.56 s, search 0.51 s): objective=232.538 imbalance=1.670 nsplit=0       \n",
      "Training PQ slice 7/8\n",
      "Clustering 65536 points in 4D to 256 clusters, redo 1 times, 25 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "CPU times: user 2min 12s, sys: 12 s, total: 2min 24s8.699 imbalance=1.738 nsplit=0       \n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = em.shape[1]\n",
    "m = 8  # number of subquantizers\n",
    "quantizer = faiss.IndexFlatIP(d)\n",
    "# 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index = faiss.IndexIVFPQ(quantizer, d, faiss_nlist, m, 8)\n",
    "index.verbose = True\n",
    "index.train(em)\n",
    "index.add(em)\n",
    "faiss.write_index(index, str(index_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5981f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(str(index_file))\n",
    "assert index.is_trained and index.ntotal == em.shape[0]\n",
    "# sanity check\n",
    "index.nprobe = 1\n",
    "k = 4\n",
    "n = 1000\n",
    "distances, ids = index.search(em[:n], k)\n",
    "for i in range(n):\n",
    "    if ids[i][0] != i:\n",
    "        print(f\"Expecting id {i} but found {ids[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8439b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:40.382359\n",
      "Saved output/item.index\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")\n",
    "print(f\"Saved {str(index_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
