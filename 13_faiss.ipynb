{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c814dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_nlist: int = 1000\n",
    "model_file = \"models/word2vec/20230131_055311/lightning_logs/version_0/checkpoints/epoch=15-step=64208.ckpt\"\n",
    "index_file = \"output/m8_w7_i20.index\"\n",
    "em_file = \"output/m8_w7_i20.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2fdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f774ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 15, 'global_step': 64208, 'pytorch-lightning_version': '1.7.7', 'state_dict': OrderedDict([('word_embeddings.weight', tensor([[ 0.7196, -0.2523,  0.0447,  ...,  0.8360,  0.6226,  0.3175],\n",
      "        [-0.0872, -1.8396,  1.0697,  ..., -0.0081,  2.1950,  1.7129],\n",
      "        [ 1.5607,  0.3383, -0.2469,  ..., -0.0354,  0.6428, -0.8423],\n",
      "        ...,\n",
      "        [ 1.5420,  0.1625, -2.4177,  ...,  2.9724,  0.2030, -1.2735],\n",
      "        [ 1.6230,  0.1426, -2.6091,  ...,  2.6237,  0.1537, -1.2714],\n",
      "        [ 1.8226,  0.2791, -2.6857,  ...,  2.6923,  0.1305, -1.2754]],\n",
      "       device='cuda:0')), ('type_embeddings.weight', tensor([[-2.0791e-01,  5.1622e-02,  2.7370e-01, -2.6897e-01, -1.7714e-01,\n",
      "          2.4166e-01, -2.6782e-01, -2.2856e-02,  2.5493e-01, -8.1043e-02,\n",
      "         -2.3945e-01, -7.7283e-02,  2.3141e-02, -1.7718e-02,  6.7999e-02,\n",
      "         -2.9145e-01, -2.5474e-01,  2.7317e-01,  2.0982e-01,  2.8213e-01,\n",
      "         -8.1954e-02,  2.3246e-01,  1.3225e-01, -1.3763e-01, -2.9451e-01,\n",
      "         -2.4344e-01,  3.9810e-01, -2.3592e-01,  2.6038e-01, -2.9222e-01,\n",
      "          5.6533e-02,  1.4423e-01],\n",
      "        [-1.2364e+00, -1.0821e-01,  1.8946e+00, -2.2643e+00, -2.4124e-01,\n",
      "          1.4587e+00, -2.0937e+00,  1.4490e-01,  1.3901e+00, -5.1036e-01,\n",
      "         -1.6881e+00, -7.6145e-01,  2.9208e-01, -5.8992e-02,  6.9971e-01,\n",
      "         -2.1008e+00, -1.8487e+00,  1.9195e+00,  1.2867e+00,  2.0899e+00,\n",
      "         -3.4966e-01,  1.3062e+00,  8.3829e-01, -9.0888e-01, -2.0646e+00,\n",
      "         -2.1558e+00, -1.6216e+01, -1.3083e+00,  1.9487e+00, -2.4810e+00,\n",
      "         -1.5273e-01,  8.8004e-01],\n",
      "        [-1.1067e+00, -2.8424e-01,  2.0291e+00, -2.3526e+00, -1.1031e-01,\n",
      "          1.5190e+00, -2.0381e+00,  1.1638e-01,  1.1883e+00, -5.1460e-01,\n",
      "         -1.7594e+00, -6.5936e-01,  3.0244e-01,  1.6168e-02,  7.9931e-01,\n",
      "         -2.2036e+00, -1.9889e+00,  1.7952e+00,  1.1998e+00,  2.1816e+00,\n",
      "         -2.2581e-01,  1.1618e+00,  8.1823e-01, -9.1169e-01, -2.0260e+00,\n",
      "         -2.0310e+00, -1.8063e+01, -1.0728e+00,  1.9103e+00, -2.4256e+00,\n",
      "         -5.9206e-02,  1.0052e+00]], device='cuda:0'))]), 'loops': {'fit_loop': {'state_dict': {}, 'epoch_loop.state_dict': {'_batches_that_stepped': 64208}, 'epoch_loop.batch_progress': {'total': {'ready': 64208, 'completed': 64208, 'started': 64208, 'processed': 64208}, 'current': {'ready': 4013, 'completed': 4013, 'started': 4013, 'processed': 4013}, 'is_last_batch': True}, 'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.batch_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.optim_progress': {'optimizer': {'step': {'total': {'ready': 64208, 'completed': 64208}, 'current': {'ready': 4013, 'completed': 4013}}, 'zero_grad': {'total': {'ready': 64208, 'completed': 64208, 'started': 64208}, 'current': {'ready': 4013, 'completed': 4013, 'started': 4013}}}, 'optimizer_position': 1}, 'epoch_loop.batch_loop.manual_loop.state_dict': {}, 'epoch_loop.batch_loop.manual_loop.optim_step_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.val_loop.state_dict': {}, 'epoch_loop.val_loop.dataloader_progress': {'total': {'ready': 16, 'completed': 16}, 'current': {'ready': 1, 'completed': 1}}, 'epoch_loop.val_loop.epoch_loop.state_dict': {}, 'epoch_loop.val_loop.epoch_loop.batch_progress': {'total': {'ready': 82, 'completed': 82, 'started': 82, 'processed': 82}, 'current': {'ready': 82, 'completed': 82, 'started': 82, 'processed': 82}, 'is_last_batch': True}, 'epoch_progress': {'total': {'ready': 16, 'completed': 15, 'started': 16, 'processed': 16}, 'current': {'ready': 16, 'completed': 15, 'started': 16, 'processed': 16}}}, 'validate_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'test_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'predict_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}}, 'callbacks': {\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 0, 'stopped_epoch': 0, 'best_score': tensor(1.7324, device='cuda:0'), 'patience': 0}, \"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\": {'monitor': 'val_loss', 'best_model_score': tensor(1.7324, device='cuda:0'), 'best_model_path': '/kaggle/working/word2vec/20230131_055311/lightning_logs/version_0/checkpoints/epoch=15-step=64208.ckpt', 'current_score': tensor(1.7324, device='cuda:0'), 'dirpath': '/kaggle/working/word2vec/20230131_055311/lightning_logs/version_0/checkpoints', 'best_k_models': {'/kaggle/working/word2vec/20230131_055311/lightning_logs/version_0/checkpoints/epoch=15-step=64208.ckpt': tensor(1.7324, device='cuda:0')}, 'kth_best_model_path': '/kaggle/working/word2vec/20230131_055311/lightning_logs/version_0/checkpoints/epoch=15-step=64208.ckpt', 'kth_value': tensor(1.7324, device='cuda:0'), 'last_model_path': ''}}, 'optimizer_states': [{'state': {0: {'step': 64208, 'exp_avg': tensor([[ 1.7580e-06, -1.7501e-07, -1.7374e-06,  ...,  1.3106e-06,\n",
      "         -5.6956e-07,  6.7410e-07],\n",
      "        [ 1.7852e-06, -2.5471e-07, -1.2645e-06,  ...,  1.2152e-06,\n",
      "         -9.5936e-07, -1.2017e-06],\n",
      "        [-7.6744e-06,  8.0614e-06,  6.0609e-07,  ...,  7.6507e-06,\n",
      "          3.0815e-06, -1.3305e-06],\n",
      "        ...,\n",
      "        [ 5.6745e-11,  9.6384e-10, -5.8759e-10,  ...,  3.9891e-10,\n",
      "          1.1193e-10, -1.7086e-09],\n",
      "        [-1.3456e-09, -4.6527e-10, -2.0419e-10,  ..., -1.8374e-09,\n",
      "          1.2812e-09,  1.1737e-09],\n",
      "        [-1.3020e-08,  7.3081e-10,  6.8868e-09,  ...,  1.3015e-08,\n",
      "         -5.9114e-08,  5.2353e-08]], device='cuda:0'), 'exp_avg_sq': tensor([[2.8995e-10, 1.0040e-10, 7.3825e-10,  ..., 1.1324e-09, 1.0768e-10,\n",
      "         2.6303e-10],\n",
      "        [1.5214e-10, 6.4780e-11, 3.2069e-10,  ..., 3.8883e-10, 6.6998e-11,\n",
      "         1.0874e-10],\n",
      "        [3.9388e-10, 1.6028e-10, 8.1139e-10,  ..., 1.1374e-09, 1.7220e-10,\n",
      "         3.0836e-10],\n",
      "        ...,\n",
      "        [5.9194e-14, 1.9265e-14, 8.0576e-14,  ..., 1.1591e-13, 5.3324e-14,\n",
      "         3.2256e-14],\n",
      "        [5.9269e-15, 1.2020e-14, 5.1731e-15,  ..., 7.6763e-15, 5.8024e-15,\n",
      "         8.1179e-15],\n",
      "        [5.9846e-15, 4.3909e-15, 1.2906e-14,  ..., 1.0394e-14, 4.5934e-14,\n",
      "         3.1765e-14]], device='cuda:0')}, 1: {'step': 64208, 'exp_avg': tensor([[-8.0086e-04, -6.9968e-04, -5.2096e-04,  6.5827e-04, -5.2721e-05,\n",
      "          5.4532e-04,  1.9409e-04, -1.2717e-03,  1.2297e-03,  6.8909e-04,\n",
      "          4.5417e-04, -8.0579e-04, -1.2268e-03, -1.5278e-03,  3.8764e-04,\n",
      "          1.2323e-03,  1.3738e-03,  1.1798e-03, -1.3924e-03,  2.1339e-03,\n",
      "         -4.7224e-04,  5.7620e-04, -2.9712e-04, -1.6472e-03,  3.7798e-04,\n",
      "          3.0222e-04, -8.2530e-03, -5.1141e-04,  2.0101e-03,  3.9651e-04,\n",
      "         -1.1375e-03, -1.8245e-03],\n",
      "        [-8.9349e-05,  8.8140e-05, -2.6414e-04, -1.5505e-04, -7.2205e-05,\n",
      "         -4.3959e-05,  4.1193e-05, -2.2806e-04,  3.2747e-06,  7.1040e-05,\n",
      "         -2.4069e-04,  1.2668e-04, -1.7215e-04,  1.8098e-04, -1.5916e-04,\n",
      "          5.8601e-05, -8.5174e-06, -7.4188e-05,  5.7058e-05, -2.4882e-05,\n",
      "          1.0968e-04, -1.4183e-04,  1.5455e-04,  1.7564e-05, -1.0497e-04,\n",
      "          2.2038e-04,  2.2763e-04,  2.0179e-04,  1.8273e-04,  1.9339e-04,\n",
      "          1.9944e-04, -5.0175e-05],\n",
      "        [ 6.7958e-05, -2.1553e-05, -7.3838e-06,  1.9992e-05, -8.4968e-05,\n",
      "          7.2005e-05,  2.0574e-05, -2.7744e-05,  1.0918e-05, -3.7937e-05,\n",
      "          1.5016e-04, -1.8382e-05,  9.5686e-05, -3.1941e-05, -1.2072e-04,\n",
      "          1.0083e-04,  4.5730e-05, -7.6544e-06,  5.3586e-05,  2.8432e-06,\n",
      "          3.5393e-05, -2.7705e-05,  2.3212e-05,  1.5697e-04,  4.2980e-05,\n",
      "          6.1969e-06, -1.9583e-05, -1.1646e-04, -3.2953e-05,  6.8190e-05,\n",
      "         -8.0573e-05, -5.8510e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[6.7762e-05, 3.5729e-05, 1.2815e-04, 1.6264e-04, 5.9445e-05, 9.3753e-05,\n",
      "         1.4879e-04, 3.7466e-05, 8.1386e-05, 3.6833e-05, 1.1003e-04, 4.4987e-05,\n",
      "         3.9952e-05, 3.3356e-05, 4.4850e-05, 1.4133e-04, 1.3120e-04, 1.2021e-04,\n",
      "         8.0161e-05, 1.5132e-04, 3.3501e-05, 8.2291e-05, 4.8392e-05, 5.5917e-05,\n",
      "         1.3974e-04, 1.5354e-04, 2.6730e-03, 7.6212e-05, 1.3431e-04, 1.6809e-04,\n",
      "         4.2166e-05, 5.3478e-05],\n",
      "        [1.0165e-06, 6.7132e-07, 1.4520e-06, 1.6416e-06, 7.4438e-07, 1.2486e-06,\n",
      "         1.6001e-06, 7.9678e-07, 1.1214e-06, 6.5203e-07, 1.4206e-06, 7.9253e-07,\n",
      "         7.9074e-07, 6.4168e-07, 8.7516e-07, 1.5799e-06, 1.4972e-06, 1.4709e-06,\n",
      "         1.0499e-06, 1.6696e-06, 5.2046e-07, 1.1912e-06, 8.8264e-07, 1.0804e-06,\n",
      "         1.5618e-06, 1.6701e-06, 2.7017e-06, 1.0278e-06, 1.5664e-06, 1.6960e-06,\n",
      "         7.3155e-07, 8.6898e-07],\n",
      "        [8.3243e-08, 7.5518e-08, 8.1716e-08, 7.2681e-08, 7.7866e-08, 7.5743e-08,\n",
      "         9.1298e-08, 9.9087e-08, 7.0557e-08, 7.6151e-08, 8.2724e-08, 8.6697e-08,\n",
      "         1.0250e-07, 8.1106e-08, 1.0434e-07, 7.8793e-08, 8.1638e-08, 9.3134e-08,\n",
      "         8.1355e-08, 8.7118e-08, 5.9203e-08, 8.1357e-08, 8.2948e-08, 1.1774e-07,\n",
      "         8.5704e-08, 7.8769e-08, 6.9295e-08, 6.8070e-08, 9.0230e-08, 6.8904e-08,\n",
      "         9.5410e-08, 7.8327e-08]], device='cuda:0')}}, 'param_groups': [{'lr': 0.003, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'params': [0, 1]}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'params': []}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'params': []}]}], 'lr_schedulers': [], 'hparams_name': 'kwargs', 'hyper_parameters': {'lr': 0.003, 'vocab_size': 1855603, 'types_size': 3, 'embedding_size': 32, 'noise_dist': None, 'negative_samples': 10, 'initializer_range': 0.02}}\n"
     ]
    }
   ],
   "source": [
    "ckp = torch.load(str(model_file))\n",
    "print(ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bbf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 1855603/1855603 [00:05<00:00, 314479.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_em.shape=(1855603, 32)\n",
      "type_em.shape=(3, 32)\n",
      "em.shape=(5566809, 32)\n"
     ]
    }
   ],
   "source": [
    "word_em = ckp[\"state_dict\"][\"word_embeddings.weight\"].cpu().numpy()\n",
    "type_em = ckp[\"state_dict\"][\"type_embeddings.weight\"].cpu().numpy()\n",
    "em = []\n",
    "for wem in tqdm(word_em):\n",
    "    for tem in type_em:\n",
    "        em.append(wem + tem)\n",
    "em = np.array(em, dtype=np.float32)\n",
    "print(f\"word_em.shape={word_em.shape}\\ntype_em.shape={type_em.shape}\\nem.shape={em.shape}\")\n",
    "assert word_em.shape[0] * type_em.shape[0] == em.shape[0]\n",
    "faiss.normalize_L2(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cae12d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save(em_file, em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60a2888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = em.shape[1]\n",
    "m = 8  # number of subquantizers\n",
    "quantizer = faiss.IndexFlatIP(d)\n",
    "# 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index = faiss.IndexIVFPQ(quantizer, d, faiss_nlist, m, 8)\n",
    "index.verbose = True\n",
    "index.train(em)\n",
    "index.add(em)\n",
    "faiss.write_index(index, str(index_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5981f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting id 12 but found 9\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(str(index_file))\n",
    "assert index.is_trained and index.ntotal == em.shape[0]\n",
    "# sanity check\n",
    "index.nprobe = 1\n",
    "k = 4\n",
    "n = 1000\n",
    "distances, ids = index.search(em[:n], k)\n",
    "for i in range(n):\n",
    "    if ids[i][0] != i:\n",
    "        print(f\"Expecting id {i} but found {ids[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8439b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:33.695480\n",
      "Saved output/m8_w7_i20.index\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")\n",
    "print(f\"Saved {str(index_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
