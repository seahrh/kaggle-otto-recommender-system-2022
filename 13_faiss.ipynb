{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c814dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_nlist: int = 1000\n",
    "model_file = \"models/word2vec/20230129_000726/lightning_logs/version_0/checkpoints/epoch=5-step=76674.ckpt\"\n",
    "index_file = \"output/item.index\"\n",
    "em_file = \"output/em.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2fdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f774ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'global_step': 76674, 'pytorch-lightning_version': '1.7.7', 'state_dict': OrderedDict([('word_embeddings.weight', tensor([[ 0.2808, -0.1675, -0.0884,  ...,  0.4609,  0.0819, -0.6246],\n",
      "        [-1.0734, -0.5885, -0.1136,  ...,  0.8975, -0.0801, -0.7135],\n",
      "        [ 0.2650,  0.7763, -0.1735,  ..., -0.4250, -0.3904,  0.3702],\n",
      "        ...,\n",
      "        [-0.1343, -0.0453, -0.5101,  ..., -0.2197, -0.2182, -0.2723],\n",
      "        [ 0.2942,  0.1648, -0.1698,  ..., -0.4534, -0.2354, -0.1568],\n",
      "        [ 0.0597, -0.2618, -0.5689,  ...,  0.0629, -0.1870,  0.0186]],\n",
      "       device='cuda:0')), ('type_embeddings.weight', tensor([[-6.0013e-02, -2.0535e-02,  2.1018e-01, -1.5173e-01,  1.8060e-01,\n",
      "          1.5254e-01, -2.0961e-01,  8.7165e-02,  1.9033e-01,  8.5203e-02,\n",
      "         -1.9330e-02,  1.0078e-03,  3.9269e-02,  8.3006e-02,  1.5975e-01,\n",
      "         -1.4394e-01,  2.7029e-02,  1.0162e-01, -2.7421e-02,  3.4179e-02,\n",
      "         -2.0325e-01,  4.9373e-02,  1.1454e-01, -1.0582e-01, -1.9734e-01,\n",
      "         -6.0054e-03, -2.3994e-01, -1.4019e-01,  5.2532e-02,  1.4536e-01,\n",
      "          1.3718e-01,  4.1978e-02],\n",
      "        [-1.6882e-01, -2.0257e-01,  5.1250e+00, -2.4858e-01,  2.6832e-01,\n",
      "          2.5058e-01, -5.5133e-01,  1.9804e-01,  6.2281e+00,  1.5965e-01,\n",
      "         -9.1341e-02, -4.3639e-02,  1.7466e-01,  1.2656e-01,  2.6100e-01,\n",
      "         -9.7827e+00,  7.4492e-02,  1.8667e-01, -6.4467e-02,  1.1357e-01,\n",
      "         -4.3102e-01,  1.3663e-01,  2.2769e-01, -2.0979e-01, -6.1014e+00,\n",
      "         -4.4530e-02, -2.4895e+00, -2.3952e-01,  1.4066e-01,  2.6058e-01,\n",
      "          2.3723e-01,  1.5510e-01],\n",
      "        [-1.6388e-01, -3.5658e-01,  6.3907e+00, -3.2168e-01,  2.6591e-01,\n",
      "          2.6871e-01, -6.4990e-01,  3.0594e-01,  7.8212e+00,  2.5861e-01,\n",
      "         -1.5028e-01, -1.2171e-01,  4.2222e-01,  1.5814e-01,  3.0295e-01,\n",
      "         -1.2349e+01,  1.6931e-01,  1.7587e-01, -1.0591e-01,  1.8965e-01,\n",
      "         -4.6138e-01,  8.2545e-02,  3.0686e-01, -3.0803e-01, -7.6125e+00,\n",
      "          3.7554e-02, -3.0606e+00, -2.0793e-01,  1.6965e-01,  3.2667e-01,\n",
      "          3.0140e-01,  2.6096e-01]], device='cuda:0'))]), 'loops': {'fit_loop': {'state_dict': {}, 'epoch_loop.state_dict': {'_batches_that_stepped': 76674}, 'epoch_loop.batch_progress': {'total': {'ready': 76674, 'completed': 76674, 'started': 76674, 'processed': 76674}, 'current': {'ready': 12779, 'completed': 12779, 'started': 12779, 'processed': 12779}, 'is_last_batch': True}, 'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.batch_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.optim_progress': {'optimizer': {'step': {'total': {'ready': 76674, 'completed': 76674}, 'current': {'ready': 12779, 'completed': 12779}}, 'zero_grad': {'total': {'ready': 76674, 'completed': 76674, 'started': 76674}, 'current': {'ready': 12779, 'completed': 12779, 'started': 12779}}}, 'optimizer_position': 1}, 'epoch_loop.batch_loop.manual_loop.state_dict': {}, 'epoch_loop.batch_loop.manual_loop.optim_step_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.val_loop.state_dict': {}, 'epoch_loop.val_loop.dataloader_progress': {'total': {'ready': 6, 'completed': 6}, 'current': {'ready': 1, 'completed': 1}}, 'epoch_loop.val_loop.epoch_loop.state_dict': {}, 'epoch_loop.val_loop.epoch_loop.batch_progress': {'total': {'ready': 261, 'completed': 261, 'started': 261, 'processed': 261}, 'current': {'ready': 261, 'completed': 261, 'started': 261, 'processed': 261}, 'is_last_batch': True}, 'epoch_progress': {'total': {'ready': 6, 'completed': 5, 'started': 6, 'processed': 6}, 'current': {'ready': 6, 'completed': 5, 'started': 6, 'processed': 6}}}, 'validate_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'test_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'predict_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}}, 'callbacks': {\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 0, 'stopped_epoch': 0, 'best_score': tensor(5.4792, device='cuda:0'), 'patience': 0}, \"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\": {'monitor': 'val_loss', 'best_model_score': tensor(5.4792, device='cuda:0'), 'best_model_path': 'models\\\\word2vec\\\\20230129_000726\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=5-step=76674.ckpt', 'current_score': tensor(5.4792, device='cuda:0'), 'dirpath': 'models\\\\word2vec\\\\20230129_000726\\\\lightning_logs\\\\version_0\\\\checkpoints', 'best_k_models': {'models\\\\word2vec\\\\20230129_000726\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=5-step=76674.ckpt': tensor(5.4792, device='cuda:0')}, 'kth_best_model_path': 'models\\\\word2vec\\\\20230129_000726\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=5-step=76674.ckpt', 'kth_value': tensor(5.4792, device='cuda:0'), 'last_model_path': ''}}, 'optimizer_states': [{'state': {0: {'step': tensor(76674.), 'exp_avg': tensor([[ 1.2425e-05,  9.5393e-06, -6.6605e-07,  ..., -4.9058e-06,\n",
      "          1.2018e-06,  1.1875e-05],\n",
      "        [ 2.9923e-06,  2.1625e-06,  9.9068e-07,  ..., -4.7649e-08,\n",
      "          3.0311e-06, -3.0538e-06],\n",
      "        [ 1.9525e-05, -1.7864e-05,  2.4621e-04,  ...,  5.5535e-06,\n",
      "          1.0228e-05, -4.1993e-06],\n",
      "        ...,\n",
      "        [ 3.5792e-11,  1.8170e-11, -1.6328e-11,  ...,  8.8324e-13,\n",
      "         -5.4310e-12,  6.5663e-12],\n",
      "        [ 9.6384e-17, -1.0612e-16,  1.0311e-15,  ...,  5.8467e-17,\n",
      "          8.1311e-17, -5.0827e-17],\n",
      "        [ 3.3266e-06, -4.6932e-06,  8.3202e-07,  ..., -1.1730e-06,\n",
      "          5.4825e-06,  1.9328e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[7.7824e-10, 8.5743e-10, 4.0066e-08,  ..., 6.6392e-10, 8.2750e-10,\n",
      "         9.1486e-10],\n",
      "        [3.7967e-10, 5.2674e-10, 3.7433e-08,  ..., 3.5831e-10, 4.7038e-10,\n",
      "         6.0596e-10],\n",
      "        [9.9142e-10, 1.1414e-09, 5.3739e-08,  ..., 9.2154e-10, 9.3250e-10,\n",
      "         1.1058e-09],\n",
      "        ...,\n",
      "        [1.4992e-10, 2.5459e-10, 8.9589e-11,  ..., 4.7888e-11, 1.5516e-10,\n",
      "         4.9743e-11],\n",
      "        [4.4485e-11, 1.0909e-11, 6.9353e-10,  ..., 2.0557e-11, 1.7703e-11,\n",
      "         1.5548e-11],\n",
      "        [3.5864e-11, 2.8981e-11, 2.1162e-11,  ..., 1.5544e-11, 4.0751e-11,\n",
      "         2.9045e-11]], device='cuda:0')}, 1: {'step': tensor(76674.), 'exp_avg': tensor([[-4.1317e-03,  1.3652e-04,  1.9889e-04,  6.1360e-03, -1.3414e-03,\n",
      "          4.7390e-04, -4.3190e-03, -4.1013e-03,  4.1692e-03, -7.6559e-03,\n",
      "         -6.5007e-03,  2.4768e-03,  8.2014e-03, -1.0128e-02, -5.0084e-03,\n",
      "         -9.1642e-03, -1.6353e-02, -3.6607e-03, -1.2626e-03,  4.0849e-03,\n",
      "         -5.3231e-04,  5.0197e-04, -9.4228e-03,  2.7250e-03, -4.1920e-03,\n",
      "         -6.4531e-03,  4.1224e-03,  4.2269e-03, -7.1357e-03, -4.3901e-03,\n",
      "          5.7815e-03, -1.3019e-02],\n",
      "        [-3.5352e-04,  5.0413e-04, -5.5564e-04,  8.4043e-04,  6.5361e-04,\n",
      "         -4.8037e-04,  2.1911e-05,  2.7665e-04,  2.0717e-03,  3.9944e-04,\n",
      "         -2.6291e-03, -1.5706e-03,  8.8712e-04, -2.1795e-04,  4.1070e-04,\n",
      "          1.4814e-03, -2.1490e-04,  3.0322e-04, -1.4965e-06,  1.1027e-03,\n",
      "          3.6513e-04, -6.4289e-04, -3.2335e-05,  7.6160e-04, -7.3059e-05,\n",
      "          2.8006e-04,  1.0781e-04,  1.1792e-03, -5.6765e-04,  1.1098e-04,\n",
      "          1.4344e-03,  1.8343e-03],\n",
      "        [-1.0852e-03,  7.0780e-04,  2.6433e-05, -6.3754e-04, -3.2510e-04,\n",
      "          1.0327e-04, -2.7396e-05,  6.7157e-04, -3.4381e-04, -7.2497e-04,\n",
      "          2.0276e-04,  7.5814e-04, -1.5566e-03, -6.5258e-04, -7.5349e-05,\n",
      "          1.2922e-04,  2.8043e-04,  4.0792e-04,  1.0325e-03,  1.8823e-04,\n",
      "         -2.1058e-04, -3.0303e-04, -6.0771e-04, -8.7776e-04, -9.7520e-05,\n",
      "          1.2540e-04, -4.1935e-06,  6.6654e-04, -5.5251e-04, -1.2081e-04,\n",
      "         -3.5210e-04,  1.4247e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7231e-04, 3.9566e-04, 4.3917e-03, 3.3523e-04, 3.1633e-04, 3.2085e-04,\n",
      "         3.5582e-04, 3.5754e-04, 6.4758e-03, 3.6982e-04, 3.8632e-04, 3.9902e-04,\n",
      "         4.1624e-04, 3.5031e-04, 3.3493e-04, 1.5477e-02, 4.0173e-04, 3.5780e-04,\n",
      "         4.0133e-04, 3.8878e-04, 3.3261e-04, 3.5510e-04, 3.4658e-04, 3.5266e-04,\n",
      "         6.2451e-03, 3.6823e-04, 1.2847e-03, 3.4180e-04, 3.7748e-04, 3.2625e-04,\n",
      "         3.3249e-04, 3.5808e-04],\n",
      "        [6.8473e-06, 7.4374e-06, 4.5270e-06, 5.9404e-06, 5.5408e-06, 5.6210e-06,\n",
      "         5.3385e-06, 6.6952e-06, 4.3289e-06, 7.2149e-06, 8.0340e-06, 7.7519e-06,\n",
      "         7.5650e-06, 6.9859e-06, 5.8919e-06, 4.2527e-06, 7.6533e-06, 6.3964e-06,\n",
      "         7.8349e-06, 7.6533e-06, 4.7977e-06, 7.0350e-06, 5.7536e-06, 6.5131e-06,\n",
      "         4.2397e-06, 7.5110e-06, 4.9036e-06, 5.8311e-06, 6.9055e-06, 5.6509e-06,\n",
      "         6.0773e-06, 7.4589e-06],\n",
      "        [2.8204e-06, 2.8930e-06, 1.6108e-06, 2.2284e-06, 2.1799e-06, 2.0113e-06,\n",
      "         1.9674e-06, 2.6349e-06, 1.6069e-06, 2.8204e-06, 2.9864e-06, 2.9598e-06,\n",
      "         3.1973e-06, 2.9423e-06, 1.8872e-06, 1.5589e-06, 3.1862e-06, 2.4144e-06,\n",
      "         3.1485e-06, 3.0570e-06, 2.0737e-06, 2.8748e-06, 2.3019e-06, 2.3823e-06,\n",
      "         1.5999e-06, 3.1299e-06, 1.8714e-06, 2.2879e-06, 2.7822e-06, 2.2482e-06,\n",
      "         2.2639e-06, 2.7669e-06]], device='cuda:0')}}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': [0, 1]}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}]}], 'lr_schedulers': [], 'hparams_name': 'kwargs', 'hyper_parameters': {'lr': 0.001, 'vocab_size': 1855603, 'types_size': 3, 'embedding_size': 32, 'noise_dist': None, 'negative_samples': 10, 'initializer_range': 0.02}}\n"
     ]
    }
   ],
   "source": [
    "ckp = torch.load(str(model_file))\n",
    "print(ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bbf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 1855603/1855603 [00:06<00:00, 300042.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_em.shape=(1855603, 32)\n",
      "type_em.shape=(3, 32)\n",
      "em.shape=(5566809, 32)\n"
     ]
    }
   ],
   "source": [
    "word_em = ckp[\"state_dict\"][\"word_embeddings.weight\"].cpu().numpy()\n",
    "type_em = ckp[\"state_dict\"][\"type_embeddings.weight\"].cpu().numpy()\n",
    "em = []\n",
    "for wem in tqdm(word_em):\n",
    "    for tem in type_em:\n",
    "        em.append(wem + tem)\n",
    "em = np.array(em, dtype=np.float32)\n",
    "print(f\"word_em.shape={word_em.shape}\\ntype_em.shape={type_em.shape}\\nem.shape={em.shape}\")\n",
    "assert word_em.shape[0] * type_em.shape[0] == em.shape[0]\n",
    "faiss.normalize_L2(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cae12d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save(em_file, em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60a2888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = em.shape[1]\n",
    "m = 8  # number of subquantizers\n",
    "quantizer = faiss.IndexFlatIP(d)\n",
    "# 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index = faiss.IndexIVFPQ(quantizer, d, faiss_nlist, m, 8)\n",
    "index.verbose = True\n",
    "index.train(em)\n",
    "index.add(em)\n",
    "faiss.write_index(index, str(index_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5981f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting id 677 but found 676\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(str(index_file))\n",
    "assert index.is_trained and index.ntotal == em.shape[0]\n",
    "# sanity check\n",
    "index.nprobe = 1\n",
    "k = 4\n",
    "n = 1000\n",
    "distances, ids = index.search(em[:n], k)\n",
    "for i in range(n):\n",
    "    if ids[i][0] != i:\n",
    "        print(f\"Expecting id {i} but found {ids[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8439b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:38.906730\n",
      "Saved output/item.index\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")\n",
    "print(f\"Saved {str(index_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
