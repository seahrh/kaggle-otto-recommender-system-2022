{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c814dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_nlist: int = 1000\n",
    "model_file = \"models/word2vec/20230131_030406/lightning_logs/version_0/checkpoints/epoch=17-step=45036.ckpt\"\n",
    "index_file = \"output/m8_w7_i10.index\"\n",
    "em_file = \"output/m8_w7_i10.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2fdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f774ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 17, 'global_step': 45036, 'pytorch-lightning_version': '1.7.7', 'state_dict': OrderedDict([('word_embeddings.weight', tensor([[ 0.4950, -0.4440,  0.6524,  ...,  0.7314,  0.6554,  0.0495],\n",
      "        [ 0.6121, -1.4272,  1.2639,  ..., -0.4463,  2.4568,  0.7586],\n",
      "        [ 1.5778,  0.1984, -0.1209,  ..., -0.0077,  0.2741, -0.9397],\n",
      "        ...,\n",
      "        [ 1.7135,  0.4625, -2.1386,  ...,  2.8617,  0.6442, -1.3882],\n",
      "        [ 1.7531,  0.5239, -2.5799,  ...,  2.7967,  0.4245, -1.2093],\n",
      "        [ 1.5163,  0.4189, -2.2055,  ...,  2.8239,  0.6003, -1.2564]],\n",
      "       device='cuda:0')), ('type_embeddings.weight', tensor([[-6.9059e-02,  4.6103e-02,  9.0372e-02, -8.6478e-02, -9.6168e-02,\n",
      "          7.5709e-02, -7.6599e-02, -1.3479e-02,  9.9222e-02, -2.9230e-02,\n",
      "         -5.8211e-02,  1.6897e-03, -1.9739e-02,  3.3352e-02,  1.2558e-02,\n",
      "         -1.2016e-01, -6.6455e-02,  1.0979e-01,  5.7964e-02,  9.7062e-02,\n",
      "         -1.7890e-02,  8.1899e-02,  3.3800e-02, -2.1709e-02, -1.1737e-01,\n",
      "         -5.6374e-02,  3.2977e-01, -9.1266e-02,  8.0708e-02, -1.1702e-01,\n",
      "          2.8802e-02,  2.6957e-02],\n",
      "        [-1.0323e+00, -3.3045e-01,  1.4220e+00, -1.6169e+00,  1.1642e-01,\n",
      "          1.1854e+00, -1.5781e+00,  4.1153e-01,  1.0785e+00, -6.0376e-01,\n",
      "         -1.3160e+00, -7.6503e-01,  2.6450e-01, -8.0394e-02,  7.2650e-01,\n",
      "         -1.5591e+00, -1.4040e+00,  1.5324e+00,  1.0919e+00,  1.5700e+00,\n",
      "         -3.3293e-01,  1.0976e+00,  8.7492e-01, -7.6212e-01, -1.5082e+00,\n",
      "         -1.5819e+00, -1.8816e+01, -1.0908e+00,  1.5305e+00, -1.7583e+00,\n",
      "         -4.1310e-01,  8.4044e-01],\n",
      "        [-8.3870e-01, -4.4359e-01,  1.4682e+00, -1.5753e+00,  2.1388e-01,\n",
      "          1.1375e+00, -1.3816e+00,  2.6646e-01,  7.9418e-01, -5.8494e-01,\n",
      "         -1.2385e+00, -6.6209e-01,  3.1710e-01,  2.0250e-02,  6.5917e-01,\n",
      "         -1.5786e+00, -1.3830e+00,  1.2677e+00,  9.2734e-01,  1.4890e+00,\n",
      "         -1.2878e-01,  8.5189e-01,  7.7307e-01, -7.2439e-01, -1.4183e+00,\n",
      "         -1.3537e+00, -2.0352e+01, -7.6927e-01,  1.3578e+00, -1.5320e+00,\n",
      "         -2.4717e-01,  8.4795e-01]], device='cuda:0'))]), 'loops': {'fit_loop': {'state_dict': {}, 'epoch_loop.state_dict': {'_batches_that_stepped': 45036}, 'epoch_loop.batch_progress': {'total': {'ready': 45036, 'completed': 45036, 'started': 45036, 'processed': 45036}, 'current': {'ready': 2502, 'completed': 2502, 'started': 2502, 'processed': 2502}, 'is_last_batch': True}, 'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.batch_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.optim_progress': {'optimizer': {'step': {'total': {'ready': 45036, 'completed': 45036}, 'current': {'ready': 2502, 'completed': 2502}}, 'zero_grad': {'total': {'ready': 45036, 'completed': 45036, 'started': 45036}, 'current': {'ready': 2502, 'completed': 2502, 'started': 2502}}}, 'optimizer_position': 1}, 'epoch_loop.batch_loop.manual_loop.state_dict': {}, 'epoch_loop.batch_loop.manual_loop.optim_step_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.val_loop.state_dict': {}, 'epoch_loop.val_loop.dataloader_progress': {'total': {'ready': 18, 'completed': 18}, 'current': {'ready': 1, 'completed': 1}}, 'epoch_loop.val_loop.epoch_loop.state_dict': {}, 'epoch_loop.val_loop.epoch_loop.batch_progress': {'total': {'ready': 52, 'completed': 52, 'started': 52, 'processed': 52}, 'current': {'ready': 52, 'completed': 52, 'started': 52, 'processed': 52}, 'is_last_batch': True}, 'epoch_progress': {'total': {'ready': 18, 'completed': 17, 'started': 18, 'processed': 18}, 'current': {'ready': 18, 'completed': 17, 'started': 18, 'processed': 18}}}, 'validate_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'test_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'predict_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}}, 'callbacks': {\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 0, 'stopped_epoch': 0, 'best_score': tensor(1.7761, device='cuda:0'), 'patience': 0}, \"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\": {'monitor': 'val_loss', 'best_model_score': tensor(1.7761, device='cuda:0'), 'best_model_path': 'models\\\\word2vec\\\\20230131_030406\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=17-step=45036.ckpt', 'current_score': tensor(1.7761, device='cuda:0'), 'dirpath': 'models\\\\word2vec\\\\20230131_030406\\\\lightning_logs\\\\version_0\\\\checkpoints', 'best_k_models': {'models\\\\word2vec\\\\20230131_030406\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=17-step=45036.ckpt': tensor(1.7761, device='cuda:0')}, 'kth_best_model_path': 'models\\\\word2vec\\\\20230131_030406\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=17-step=45036.ckpt', 'kth_value': tensor(1.7761, device='cuda:0'), 'last_model_path': ''}}, 'optimizer_states': [{'state': {0: {'step': tensor(45036.), 'exp_avg': tensor([[-3.9741e-07,  5.0194e-07,  3.3233e-07,  ..., -2.6111e-06,\n",
      "         -1.6118e-06,  9.5833e-07],\n",
      "        [ 1.4809e-06, -7.0305e-07,  1.8773e-07,  ..., -1.0270e-07,\n",
      "          1.3540e-06, -1.3704e-06],\n",
      "        [ 1.4010e-07,  8.8600e-07, -3.1082e-06,  ...,  3.6397e-06,\n",
      "         -9.1055e-07, -1.8089e-06],\n",
      "        ...,\n",
      "        [ 1.5614e-07, -7.9950e-09,  3.6833e-08,  ..., -1.4759e-09,\n",
      "          2.2954e-08,  1.0027e-07],\n",
      "        [-2.0245e-09,  1.1913e-09,  2.1012e-09,  ...,  1.8381e-10,\n",
      "         -2.0103e-09,  5.1111e-10],\n",
      "        [ 2.4109e-09, -4.5404e-09,  2.8425e-09,  ...,  5.5495e-10,\n",
      "         -1.9795e-09,  1.1802e-10]], device='cuda:0'), 'exp_avg_sq': tensor([[2.2554e-10, 1.3357e-10, 4.0547e-10,  ..., 5.5789e-10, 1.2887e-10,\n",
      "         1.8893e-10],\n",
      "        [1.3522e-10, 7.7626e-11, 2.4462e-10,  ..., 2.5774e-10, 9.5094e-11,\n",
      "         1.2256e-10],\n",
      "        [3.2572e-10, 1.6299e-10, 5.1480e-10,  ..., 5.3273e-10, 1.9152e-10,\n",
      "         2.8459e-10],\n",
      "        ...,\n",
      "        [1.5256e-14, 1.7142e-14, 1.1664e-14,  ..., 1.1057e-14, 1.9570e-14,\n",
      "         9.6697e-15],\n",
      "        [4.2488e-15, 9.4015e-15, 4.1382e-15,  ..., 3.9868e-15, 1.3352e-14,\n",
      "         8.4060e-15],\n",
      "        [2.8654e-14, 5.1456e-14, 1.0151e-14,  ..., 2.0632e-14, 2.6021e-14,\n",
      "         2.6317e-14]], device='cuda:0')}, 1: {'step': tensor(45036.), 'exp_avg': tensor([[ 3.1684e-03,  2.0048e-03, -2.2722e-03, -2.1710e-04, -4.3476e-03,\n",
      "          3.3473e-04, -3.8939e-04, -1.6059e-04, -9.4252e-04,  3.1902e-03,\n",
      "          1.6249e-03,  1.6565e-03, -1.8902e-03, -8.6259e-04, -7.4735e-04,\n",
      "          1.6175e-03,  9.1078e-04,  6.9855e-04, -2.1383e-03,  1.4294e-03,\n",
      "          6.3075e-04, -5.5868e-04, -9.6130e-04, -1.0199e-03,  2.2754e-04,\n",
      "         -1.6614e-03, -9.3222e-04,  1.3684e-05, -1.5581e-03,  1.8778e-03,\n",
      "          6.1751e-04, -1.5015e-03],\n",
      "        [ 8.4003e-05, -1.8427e-04,  3.9209e-04, -2.2478e-04,  1.4360e-05,\n",
      "          3.2890e-04, -3.4820e-04, -4.7486e-05,  1.0122e-06, -2.7674e-05,\n",
      "         -8.9158e-05, -1.3882e-05,  1.0688e-04, -1.9132e-04,  1.5123e-04,\n",
      "         -1.7984e-04, -3.8780e-04,  1.9361e-04,  3.2398e-04,  1.5708e-04,\n",
      "          1.7125e-04, -8.1644e-05,  9.3085e-05, -6.2504e-04,  2.8424e-05,\n",
      "         -4.1441e-04,  3.8101e-04, -3.4662e-04,  7.7431e-05, -1.8241e-04,\n",
      "         -2.9520e-04,  1.3686e-04],\n",
      "        [-1.0630e-06,  2.0119e-05,  3.2753e-05,  4.8686e-05, -9.8901e-05,\n",
      "         -9.6343e-05,  2.2411e-05, -5.2086e-05, -9.6756e-05, -9.9851e-05,\n",
      "          7.4932e-05, -1.1975e-05, -6.6285e-05,  5.7736e-05, -8.3670e-05,\n",
      "         -7.2345e-06, -5.4544e-05, -2.8186e-05, -1.3825e-04, -2.5453e-05,\n",
      "         -1.3839e-05, -9.5748e-05, -1.4025e-05,  1.8185e-05,  2.9747e-05,\n",
      "          7.3247e-06,  2.7650e-05, -1.7132e-05,  5.0297e-05,  3.8459e-05,\n",
      "          2.7144e-06, -7.7345e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[7.2479e-05, 4.2196e-05, 1.1773e-04, 1.3362e-04, 5.1759e-05, 9.0136e-05,\n",
      "         1.3424e-04, 4.1993e-05, 7.8901e-05, 4.3542e-05, 1.0770e-04, 5.8090e-05,\n",
      "         3.8337e-05, 3.5641e-05, 4.9264e-05, 1.2667e-04, 1.1724e-04, 1.1696e-04,\n",
      "         7.9437e-05, 1.3893e-04, 3.3689e-05, 7.9274e-05, 6.0025e-05, 5.8719e-05,\n",
      "         1.2504e-04, 1.4527e-04, 3.5091e-03, 7.6762e-05, 1.2745e-04, 1.4150e-04,\n",
      "         4.3073e-05, 5.9222e-05],\n",
      "        [8.1763e-07, 6.7222e-07, 1.0660e-06, 1.2467e-06, 6.6162e-07, 9.6733e-07,\n",
      "         1.2641e-06, 7.3326e-07, 8.2728e-07, 6.4565e-07, 1.0501e-06, 7.5152e-07,\n",
      "         7.0590e-07, 6.4299e-07, 6.9890e-07, 1.1620e-06, 1.1556e-06, 1.1398e-06,\n",
      "         8.6338e-07, 1.2905e-06, 4.6339e-07, 9.4149e-07, 7.9362e-07, 8.9911e-07,\n",
      "         1.1767e-06, 1.2840e-06, 1.1252e-06, 8.4174e-07, 1.2055e-06, 1.2971e-06,\n",
      "         6.3241e-07, 7.1342e-07],\n",
      "        [7.4646e-08, 6.5900e-08, 7.4042e-08, 6.9591e-08, 6.5566e-08, 6.8402e-08,\n",
      "         8.9726e-08, 7.8906e-08, 5.8930e-08, 6.1806e-08, 7.7122e-08, 7.0386e-08,\n",
      "         8.0156e-08, 7.1886e-08, 7.8226e-08, 6.8497e-08, 7.8129e-08, 7.9888e-08,\n",
      "         7.0546e-08, 8.6424e-08, 4.6312e-08, 6.7315e-08, 7.8979e-08, 1.0111e-07,\n",
      "         7.7831e-08, 7.1500e-08, 3.7869e-08, 6.0276e-08, 8.5060e-08, 6.5079e-08,\n",
      "         7.4791e-08, 6.6310e-08]], device='cuda:0')}}, 'param_groups': [{'lr': 0.003, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': [0, 1]}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}]}], 'lr_schedulers': [], 'hparams_name': 'kwargs', 'hyper_parameters': {'lr': 0.003, 'vocab_size': 1855603, 'types_size': 3, 'embedding_size': 32, 'noise_dist': None, 'negative_samples': 10, 'initializer_range': 0.02}}\n"
     ]
    }
   ],
   "source": [
    "ckp = torch.load(str(model_file))\n",
    "print(ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bbf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 1855603/1855603 [00:05<00:00, 310753.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_em.shape=(1855603, 32)\n",
      "type_em.shape=(3, 32)\n",
      "em.shape=(5566809, 32)\n"
     ]
    }
   ],
   "source": [
    "word_em = ckp[\"state_dict\"][\"word_embeddings.weight\"].cpu().numpy()\n",
    "type_em = ckp[\"state_dict\"][\"type_embeddings.weight\"].cpu().numpy()\n",
    "em = []\n",
    "for wem in tqdm(word_em):\n",
    "    for tem in type_em:\n",
    "        em.append(wem + tem)\n",
    "em = np.array(em, dtype=np.float32)\n",
    "print(f\"word_em.shape={word_em.shape}\\ntype_em.shape={type_em.shape}\\nem.shape={em.shape}\")\n",
    "assert word_em.shape[0] * type_em.shape[0] == em.shape[0]\n",
    "faiss.normalize_L2(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cae12d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save(em_file, em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60a2888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = em.shape[1]\n",
    "m = 8  # number of subquantizers\n",
    "quantizer = faiss.IndexFlatIP(d)\n",
    "# 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index = faiss.IndexIVFPQ(quantizer, d, faiss_nlist, m, 8)\n",
    "index.verbose = True\n",
    "index.train(em)\n",
    "index.add(em)\n",
    "faiss.write_index(index, str(index_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5981f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(str(index_file))\n",
    "assert index.is_trained and index.ntotal == em.shape[0]\n",
    "# sanity check\n",
    "index.nprobe = 1\n",
    "k = 4\n",
    "n = 1000\n",
    "distances, ids = index.search(em[:n], k)\n",
    "for i in range(n):\n",
    "    if ids[i][0] != i:\n",
    "        print(f\"Expecting id {i} but found {ids[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8439b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:30.362810\n",
      "Saved output/m8_w7_i10.index\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")\n",
    "print(f\"Saved {str(index_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
