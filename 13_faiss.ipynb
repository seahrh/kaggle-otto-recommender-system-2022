{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c814dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import scml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_nlist: int = 1000\n",
    "model_file = \"models/word2vec/20230130_025602/lightning_logs/version_0/checkpoints/epoch=0-step=10697.ckpt\"\n",
    "index_file = \"output/20230130_025602.index\"\n",
    "em_file = \"output/20230130_025602.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2fdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = scml.Timer()\n",
    "tim.start()\n",
    "percentiles=[.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .99]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "pd.set_option(\"use_inf_as_na\", True)\n",
    "pd.set_option(\"max_info_columns\", 9999)\n",
    "pd.set_option(\"display.max_columns\", 9999)\n",
    "pd.set_option(\"display.max_rows\", 9999)\n",
    "pd.set_option('max_colwidth', 9999)\n",
    "tqdm.pandas()\n",
    "scml.seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f774ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'global_step': 10697, 'pytorch-lightning_version': '1.7.7', 'state_dict': OrderedDict([('word_embeddings.weight', tensor([[-0.2121,  0.3218,  0.1166,  ..., -0.1201,  0.0314,  0.1183],\n",
      "        [-0.0597,  0.4598, -0.0143,  ...,  0.3505, -0.1453, -0.0897],\n",
      "        [-0.1908,  0.0925,  0.1736,  ..., -0.1001,  0.0232, -0.1467],\n",
      "        ...,\n",
      "        [-0.1057, -0.2042,  0.1163,  ...,  0.0912,  0.0080, -0.2655],\n",
      "        [ 0.0415,  0.0685,  0.1066,  ..., -0.2149, -0.5060,  0.0733],\n",
      "        [-0.1519, -0.3222, -0.2716,  ...,  0.0119, -0.3107,  0.1295]],\n",
      "       device='cuda:0')), ('type_embeddings.weight', tensor([[ 5.0394e-02,  6.8741e-02, -1.3322e-02, -1.0164e-02,  4.5324e-02,\n",
      "         -3.1418e-02,  3.4683e-03, -2.5713e-03, -3.4160e-02,  3.5731e-02,\n",
      "          2.9226e-02,  3.9432e-02, -1.0001e-02,  7.0614e-02,  1.7031e-02,\n",
      "          2.2364e-02,  3.6731e-02, -2.7171e-02, -3.5089e-02,  1.9941e-02,\n",
      "          1.0660e-01, -5.0294e-02, -3.6797e-02,  4.6865e-02,  1.9488e-02,\n",
      "          2.3824e-02,  1.1158e-01,  3.9888e-02, -2.5116e-02,  2.6447e-02,\n",
      "          1.1323e-03, -4.9811e-02],\n",
      "        [ 9.5944e-03,  4.0473e-02,  3.7849e-01, -1.0575e-01,  2.3664e-01,\n",
      "          6.4016e-02, -1.5223e-01,  2.4640e+00,  4.6764e-01,  8.9443e-02,\n",
      "          2.0904e-02,  5.3298e-02,  3.2276e-02,  9.8982e-02,  5.2750e-01,\n",
      "         -8.9765e-01,  5.9013e-02,  3.3391e-02, -6.7426e-02,  8.3692e-02,\n",
      "         -9.6459e+00, -2.6308e-02,  2.9544e-02, -2.4675e-02, -5.2374e-01,\n",
      "          1.7877e-02, -9.9352e+00, -6.1468e-02,  1.1623e-02,  1.1253e-01,\n",
      "          2.0873e+00, -6.1864e-03],\n",
      "        [ 1.3008e-02, -1.4047e-03,  4.0820e-01, -1.3035e-01,  2.6131e-01,\n",
      "          7.6664e-02, -1.6325e-01,  2.7536e+00,  5.2269e-01,  5.0998e-02,\n",
      "          2.9070e-02,  2.9822e-03,  2.9423e-02,  8.4882e-02,  5.7338e-01,\n",
      "         -9.8577e-01,  2.6852e-02,  2.0897e-02, -3.4963e-02,  9.6057e-02,\n",
      "         -1.0852e+01, -2.6563e-02,  5.6060e-02, -4.9295e-02, -5.8362e-01,\n",
      "          2.5810e-02, -1.1180e+01, -6.6801e-02, -8.8101e-03,  1.3164e-01,\n",
      "          2.3273e+00, -2.2519e-02]], device='cuda:0'))]), 'loops': {'fit_loop': {'state_dict': {}, 'epoch_loop.state_dict': {'_batches_that_stepped': 10697}, 'epoch_loop.batch_progress': {'total': {'ready': 10697, 'completed': 10697, 'started': 10697, 'processed': 10697}, 'current': {'ready': 10697, 'completed': 10697, 'started': 10697, 'processed': 10697}, 'is_last_batch': True}, 'epoch_loop.scheduler_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.batch_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.state_dict': {}, 'epoch_loop.batch_loop.optimizer_loop.optim_progress': {'optimizer': {'step': {'total': {'ready': 10697, 'completed': 10697}, 'current': {'ready': 10697, 'completed': 10697}}, 'zero_grad': {'total': {'ready': 10697, 'completed': 10697, 'started': 10697}, 'current': {'ready': 10697, 'completed': 10697, 'started': 10697}}}, 'optimizer_position': 1}, 'epoch_loop.batch_loop.manual_loop.state_dict': {}, 'epoch_loop.batch_loop.manual_loop.optim_step_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.val_loop.state_dict': {}, 'epoch_loop.val_loop.dataloader_progress': {'total': {'ready': 1, 'completed': 1}, 'current': {'ready': 1, 'completed': 1}}, 'epoch_loop.val_loop.epoch_loop.state_dict': {}, 'epoch_loop.val_loop.epoch_loop.batch_progress': {'total': {'ready': 219, 'completed': 219, 'started': 219, 'processed': 219}, 'current': {'ready': 219, 'completed': 219, 'started': 219, 'processed': 219}, 'is_last_batch': True}, 'epoch_progress': {'total': {'ready': 1, 'completed': 0, 'started': 1, 'processed': 1}, 'current': {'ready': 1, 'completed': 0, 'started': 1, 'processed': 1}}}, 'validate_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'test_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'is_last_batch': False}}, 'predict_loop': {'state_dict': {}, 'dataloader_progress': {'total': {'ready': 0, 'completed': 0}, 'current': {'ready': 0, 'completed': 0}}, 'epoch_loop.state_dict': {}, 'epoch_loop.batch_progress': {'total': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}, 'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}}, 'callbacks': {\"EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}\": {'wait_count': 0, 'stopped_epoch': 0, 'best_score': tensor(5.2967, device='cuda:0'), 'patience': 0}, \"ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\": {'monitor': 'val_loss', 'best_model_score': tensor(5.2967, device='cuda:0'), 'best_model_path': 'models\\\\word2vec\\\\20230130_025602\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=0-step=10697.ckpt', 'current_score': tensor(5.2967, device='cuda:0'), 'dirpath': 'models\\\\word2vec\\\\20230130_025602\\\\lightning_logs\\\\version_0\\\\checkpoints', 'best_k_models': {'models\\\\word2vec\\\\20230130_025602\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=0-step=10697.ckpt': tensor(5.2967, device='cuda:0')}, 'kth_best_model_path': 'models\\\\word2vec\\\\20230130_025602\\\\lightning_logs\\\\version_0\\\\checkpoints\\\\epoch=0-step=10697.ckpt', 'kth_value': tensor(5.2967, device='cuda:0'), 'last_model_path': ''}}, 'optimizer_states': [{'state': {0: {'step': tensor(10697.), 'exp_avg': tensor([[ 4.5701e-06,  4.5350e-06, -4.0880e-06,  ...,  3.4329e-06,\n",
      "          2.2659e-07,  2.3956e-06],\n",
      "        [ 2.8293e-06,  2.1244e-06, -6.9885e-06,  ...,  8.4232e-07,\n",
      "          6.7644e-07, -3.6344e-06],\n",
      "        [-7.9080e-07,  1.6901e-06, -1.7420e-06,  ..., -8.1030e-06,\n",
      "          9.4688e-06, -1.4704e-05],\n",
      "        ...,\n",
      "        [-8.5429e-08,  3.8677e-07, -1.3827e-06,  ..., -1.4954e-07,\n",
      "         -5.2592e-08,  1.9790e-07],\n",
      "        [-7.3421e-08, -1.4530e-06, -9.8030e-07,  ..., -1.0742e-06,\n",
      "         -8.8411e-07, -6.1177e-07],\n",
      "        [-7.9371e-09,  4.5440e-09,  1.7186e-09,  ...,  2.5018e-09,\n",
      "          2.4233e-08,  6.1121e-09]], device='cuda:0'), 'exp_avg_sq': tensor([[5.4425e-10, 5.1656e-10, 7.8264e-10,  ..., 5.8226e-10, 2.2354e-09,\n",
      "         5.7376e-10],\n",
      "        [2.9688e-10, 3.0924e-10, 5.0188e-10,  ..., 3.3096e-10, 2.0013e-09,\n",
      "         3.0528e-10],\n",
      "        [6.8699e-10, 7.1016e-10, 9.3575e-10,  ..., 6.8794e-10, 2.5276e-09,\n",
      "         7.0574e-10],\n",
      "        ...,\n",
      "        [7.0275e-12, 9.2313e-12, 2.5774e-11,  ..., 1.3105e-11, 1.7200e-11,\n",
      "         1.0681e-11],\n",
      "        [1.0209e-11, 1.0183e-11, 1.6890e-11,  ..., 1.5239e-11, 5.0985e-11,\n",
      "         9.5870e-12],\n",
      "        [4.0730e-12, 3.2150e-12, 4.0006e-12,  ..., 3.9532e-12, 5.4775e-12,\n",
      "         3.9421e-12]], device='cuda:0')}, 1: {'step': tensor(10697.), 'exp_avg': tensor([[-4.6407e-04,  1.4676e-03,  3.1664e-04, -1.9433e-03,  3.0708e-03,\n",
      "          3.7394e-03,  8.3855e-04,  3.8103e-03,  5.5637e-04, -1.6043e-03,\n",
      "         -2.1649e-03,  4.6501e-04, -3.1298e-03,  3.2469e-03,  2.0214e-03,\n",
      "          2.8997e-05,  9.5071e-04,  3.2094e-03, -2.9842e-03,  3.0064e-03,\n",
      "          4.2842e-03,  3.7707e-05,  1.3652e-04, -2.9166e-03, -4.1581e-03,\n",
      "         -6.6028e-05,  4.3875e-03, -4.8226e-04, -1.6898e-03, -4.9582e-04,\n",
      "          1.9757e-03, -8.5362e-04],\n",
      "        [-7.1886e-05,  4.2519e-04, -2.8875e-05, -1.7716e-05,  4.9895e-04,\n",
      "         -1.4853e-04, -2.3572e-04,  5.3821e-04,  6.6826e-04,  2.8940e-04,\n",
      "          2.6404e-04,  1.9726e-05,  1.7018e-04, -3.9310e-05,  4.6300e-04,\n",
      "         -8.9480e-05, -1.4253e-04,  3.5983e-04, -3.9036e-04,  8.0113e-05,\n",
      "          3.9296e-04, -2.1464e-04, -1.1568e-04, -4.3610e-04, -1.1642e-03,\n",
      "          5.7442e-04,  8.4974e-05, -6.4048e-04,  2.4869e-04,  6.0531e-05,\n",
      "          1.6327e-04,  7.7985e-05],\n",
      "        [-1.2059e-04,  1.5795e-04,  8.1497e-05, -5.5262e-05, -3.8448e-05,\n",
      "          2.2756e-04,  1.9832e-05,  3.0044e-04,  1.1609e-04, -1.7777e-04,\n",
      "          1.7665e-04,  1.3870e-04, -7.8214e-05,  5.2152e-04,  4.3486e-05,\n",
      "         -3.3265e-04, -1.2859e-04,  2.1647e-04,  1.1736e-04,  1.0860e-04,\n",
      "          2.1299e-04,  1.1349e-05, -6.1007e-05, -9.9664e-06, -2.6271e-04,\n",
      "         -1.5326e-04,  4.3800e-04, -4.3795e-05, -2.0323e-04, -5.3799e-05,\n",
      "         -8.2448e-05,  8.3440e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[3.2063e-04, 3.1444e-04, 2.3794e-04, 1.5625e-04, 1.6195e-04, 2.4305e-04,\n",
      "         1.8212e-04, 7.1527e-04, 3.2353e-04, 1.3389e-04, 1.6858e-04, 1.6795e-04,\n",
      "         1.3711e-04, 2.2283e-04, 2.0562e-04, 3.4254e-04, 1.7905e-04, 2.3343e-04,\n",
      "         1.6415e-04, 1.3973e-04, 5.8473e-03, 3.1141e-04, 2.3739e-04, 2.7352e-04,\n",
      "         2.9525e-04, 1.7992e-04, 6.2134e-03, 2.8493e-04, 2.0251e-04, 1.4381e-04,\n",
      "         5.9031e-04, 2.4044e-04],\n",
      "        [1.4889e-06, 1.8005e-06, 1.9299e-06, 1.5158e-06, 1.6983e-06, 1.7218e-06,\n",
      "         1.7280e-06, 1.9130e-06, 2.0217e-06, 1.3701e-06, 1.3857e-06, 1.4271e-06,\n",
      "         1.4608e-06, 1.6291e-06, 1.7343e-06, 2.2287e-06, 1.3015e-06, 1.6396e-06,\n",
      "         1.3813e-06, 1.4705e-06, 1.7677e-06, 1.5315e-06, 1.8524e-06, 1.9852e-06,\n",
      "         2.1011e-06, 1.4145e-06, 1.7463e-06, 1.8773e-06, 1.4620e-06, 1.4826e-06,\n",
      "         1.8576e-06, 1.6969e-06],\n",
      "        [2.7781e-06, 1.9712e-06, 1.4156e-06, 7.6874e-07, 8.9605e-07, 1.8184e-06,\n",
      "         1.1425e-06, 8.1513e-07, 2.3979e-06, 7.3367e-07, 1.0022e-06, 9.8289e-07,\n",
      "         6.8604e-07, 1.3081e-06, 7.9225e-07, 1.5782e-06, 1.1242e-06, 1.8146e-06,\n",
      "         8.9231e-07, 6.2529e-07, 8.0043e-07, 2.5829e-06, 1.5886e-06, 1.8635e-06,\n",
      "         1.7787e-06, 1.2614e-06, 8.3367e-07, 2.3219e-06, 1.4454e-06, 7.1074e-07,\n",
      "         8.6636e-07, 1.6247e-06]], device='cuda:0')}}, 'param_groups': [{'lr': 0.003, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': [0, 1]}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}, {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'params': []}]}], 'lr_schedulers': [], 'hparams_name': 'kwargs', 'hyper_parameters': {'lr': 0.003, 'vocab_size': 1855603, 'types_size': 3, 'embedding_size': 32, 'noise_dist': None, 'negative_samples': 10, 'initializer_range': 0.02}}\n"
     ]
    }
   ],
   "source": [
    "ckp = torch.load(str(model_file))\n",
    "print(ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25bbf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 1855603/1855603 [00:06<00:00, 300870.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_em.shape=(1855603, 32)\n",
      "type_em.shape=(3, 32)\n",
      "em.shape=(5566809, 32)\n"
     ]
    }
   ],
   "source": [
    "word_em = ckp[\"state_dict\"][\"word_embeddings.weight\"].cpu().numpy()\n",
    "type_em = ckp[\"state_dict\"][\"type_embeddings.weight\"].cpu().numpy()\n",
    "em = []\n",
    "for wem in tqdm(word_em):\n",
    "    for tem in type_em:\n",
    "        em.append(wem + tem)\n",
    "em = np.array(em, dtype=np.float32)\n",
    "print(f\"word_em.shape={word_em.shape}\\ntype_em.shape={type_em.shape}\\nem.shape={em.shape}\")\n",
    "assert word_em.shape[0] * type_em.shape[0] == em.shape[0]\n",
    "faiss.normalize_L2(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cae12d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.save(em_file, em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60a2888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = em.shape[1]\n",
    "m = 8  # number of subquantizers\n",
    "quantizer = faiss.IndexFlatIP(d)\n",
    "# 8 specifies that each sub-vector is encoded as 8 bits\n",
    "index = faiss.IndexIVFPQ(quantizer, d, faiss_nlist, m, 8)\n",
    "index.verbose = True\n",
    "index.train(em)\n",
    "index.add(em)\n",
    "faiss.write_index(index, str(index_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5981f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting id 5 but found 4\n",
      "Expecting id 47 but found 46\n",
      "Expecting id 182 but found 181\n",
      "Expecting id 185 but found 184\n",
      "Expecting id 191 but found 190\n",
      "Expecting id 236 but found 235\n",
      "Expecting id 296 but found 295\n",
      "Expecting id 380 but found 379\n",
      "Expecting id 389 but found 388\n",
      "Expecting id 524 but found 523\n",
      "Expecting id 527 but found 526\n",
      "Expecting id 572 but found 571\n",
      "Expecting id 590 but found 589\n",
      "Expecting id 752 but found 751\n",
      "Expecting id 788 but found 787\n",
      "Expecting id 866 but found 865\n",
      "Expecting id 938 but found 937\n"
     ]
    }
   ],
   "source": [
    "index = faiss.read_index(str(index_file))\n",
    "assert index.is_trained and index.ntotal == em.shape[0]\n",
    "# sanity check\n",
    "index.nprobe = 1\n",
    "k = 4\n",
    "n = 1000\n",
    "distances, ids = index.search(em[:n], k)\n",
    "for i in range(n):\n",
    "    if ids[i][0] != i:\n",
    "        print(f\"Expecting id {i} but found {ids[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8439b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 0:00:33.115153\n",
      "Saved output/20230130_025602.index\n"
     ]
    }
   ],
   "source": [
    "tim.stop()\n",
    "print(f\"Total time taken {str(tim.elapsed)}\")\n",
    "print(f\"Saved {str(index_file)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
